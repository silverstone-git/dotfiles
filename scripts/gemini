#!/home/cyto/miniforge3/envs/mcp/bin/python
from openai import AsyncOpenAI
import asyncio
import os
from sys import argv

client= AsyncOpenAI(base_url= "https://generativelanguage.googleapis.com/v1beta/openai/", api_key= os.environ.get('OPENAI_API_KEY'))

# client.

async def main():
    response = await client.chat.completions.create(
      model="gemini-2.5-flash-preview-04-17",
      messages=[
        {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": ' '.join(argv[1:])}
      ],
      stream=True
    )

    async for chunk in response:
        # print(chunk.choices[0].delta)
        if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="", flush=True)


asyncio.run(main())
